# Full dataset training configuration
data:
  train_path: "data/processed_full/train.pkl"
  val_path: "data/processed_full/test.pkl"
  test_path: "data/processed_full/test.pkl"
  batch_size: 32  # Increased for full training
  num_workers: 8  # More workers for large dataset
  pin_memory: true
  shuffle: true
  include_pocket: true
  augment: true
  max_atoms: 50

model:
  atom_types: 11
  bond_types: 4
  hidden_dim: 256  # Larger model for full data
  pocket_dim: 256
  num_layers: 6    # Deeper network
  max_radius: 12.0
  max_pocket_atoms: 1500  # More pocket atoms for better representation
  conditioning_type: "add"

sde:
  sigma_min: 0.01
  sigma_max: 50.0
  num_steps: 1000
  beta_schedule: "cosine"
  prediction_type: "score"

training:
  num_epochs: 100  # More epochs for full training
  lr: 0.0001
  weight_decay: 0.0001
  grad_clip_norm: 1.0
  gradient_accumulation_steps: 2  # Effective batch size = 32 * 2 = 64
  
optimizer:
  type: "adamw"
  lr: 0.0001
  betas: [0.9, 0.999]
  weight_decay: 0.0001
  
scheduler:
  type: "cosine_annealing"
  T_max: 100
  eta_min: 0.00001
  warmup_epochs: 5  # Warmup for stable training
  
loss_weights:
  position_loss: 1.0
  atom_type_loss: 0.2  # Increased importance
  bond_type_loss: 0.2
  
logging:
  project_name: "crossdock-full-training"
  log_every_n_steps: 50
  val_check_interval: 1000
  save_top_k: 5
  save_path: "models_full/"
  
early_stopping:
  monitor: "val_total_loss"
  patience: 15  # More patience for large dataset
  min_delta: 0.001
  
generation:
  num_molecules: 100
  max_atoms: 50
  guidance_scale: 1.0
  num_steps: 1000
  sampling_method: "ddpm"

# Memory optimization
memory_optimization:
  gradient_checkpointing: true
  mixed_precision: true
  max_batch_size_auto_tune: true
  
# Distributed training (if using multiple GPUs)
distributed:
  enabled: false
  world_size: 1
  local_rank: 0